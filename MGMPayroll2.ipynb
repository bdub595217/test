{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import urllib\n",
    "from sodapy import Socrata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Requests made without an app_token will be subject to strict throttling limits.\n"
     ]
    }
   ],
   "source": [
    "client = Socrata(\"data.montgomeryal.gov\", None)\n",
    "results = client.get(\"pjb8-sd6v\", limit=10000)\n",
    "raw_data = pd.DataFrame.from_records(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2405 entries, 0 to 2404\n",
      "Data columns (total 12 columns):\n",
      "annual_salary      2405 non-null object\n",
      "annualsalaryytd    2400 non-null object\n",
      "department         2405 non-null object\n",
      "grade              2405 non-null object\n",
      "hire_date          2405 non-null object\n",
      "name               2405 non-null object\n",
      "otherpayamt        212 non-null object\n",
      "otherpaydesc       1313 non-null object\n",
      "overtimeamt        2311 non-null object\n",
      "position_title     2405 non-null object\n",
      "positiontype       2405 non-null object\n",
      "step               2405 non-null object\n",
      "dtypes: object(12)\n",
      "memory usage: 225.5+ KB\n"
     ]
    }
   ],
   "source": [
    "#create copy of raw_data as data\n",
    "data = raw_data.sort_index()\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2405 entries, 0 to 2404\n",
      "Data columns (total 12 columns):\n",
      "annual_salary      2405 non-null float64\n",
      "annualsalaryytd    2400 non-null float64\n",
      "department         2405 non-null object\n",
      "grade              2405 non-null object\n",
      "hire_date          2405 non-null datetime64[ns]\n",
      "name               2405 non-null object\n",
      "otherpayamt        2405 non-null float64\n",
      "otherpaydesc       1313 non-null object\n",
      "overtimeamt        2405 non-null float64\n",
      "position_title     2405 non-null object\n",
      "positiontype       2405 non-null object\n",
      "step               2405 non-null int64\n",
      "dtypes: datetime64[ns](1), float64(4), int64(1), object(6)\n",
      "memory usage: 225.5+ KB\n"
     ]
    }
   ],
   "source": [
    "#convert columns to appropriate types, data cleanup, and reset the index\n",
    "cat_cols = pd.Index(['department', 'otherpaydesc', 'positiontype'])\n",
    "#data[cat_cols] = data[cat_cols].apply(pd.Categorical)\n",
    "\n",
    "data['otherpayamt'] = data['otherpayamt'].fillna(0) #replace null values with 0s\n",
    "data['overtimeamt'] = data['overtimeamt'].fillna(0) #replace null values with 0s\n",
    "data['hire_date'] = pd.to_datetime(data['hire_date'])\n",
    "\n",
    "num_cols = pd.Index(['annual_salary', 'annualsalaryytd', 'otherpayamt', 'overtimeamt', 'step'])\n",
    "data[num_cols] = data[num_cols].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "#data.set_index('hire_date', drop=False, inplace=True)\n",
    "\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dictionary for departments by type and affix to dataframe\n",
    "positions = data.department.unique()\n",
    "types = ['Public Works', 'Public Safety', 'Maintenance/Sanitation', \n",
    "         'Public Works', 'Public Works', 'Maintenance/Sanitation', \n",
    "         'Public Safety', 'Public Safety', 'Public Works', 'Public Works', \n",
    "         'Admin & Judicial', 'Maintenance/Sanitation', 'Public Works', \n",
    "         'Admin & Judicial', 'Maintenance/Sanitation',  'Admin & Judicial', 'Admin & Judicial',\n",
    "         'Maintenance/Sanitation', 'Public Safety', 'Admin & Judicial', \n",
    "         'Public Works', 'Admin & Judicial', 'Admin & Judicial', \n",
    "         'Admin & Judicial', 'Public Safety', 'Public Safety', \n",
    "         'Admin & Judicial', 'Admin & Judicial', 'Admin & Judicial', \n",
    "         'Admin & Judicial', 'Public Safety']\n",
    "gov_dict = dict(zip(positions, types))\n",
    "data['category'] = data['department'].map(gov_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "# Create a class to select numerical or categorical columns \n",
    "# since Scikit-Learn doesn't handle DataFrames yet\n",
    "class DataFrameSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, attribute_names):\n",
    "        self.attribute_names = attribute_names\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X[self.attribute_names].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition of the CategoricalEncoder class, copied from PR #9151.\n",
    "# Just run this cell, or copy it to your code, do not try to understand it (yet).\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.utils import check_array\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scipy import sparse\n",
    "\n",
    "class CategoricalEncoder(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Encode categorical features as a numeric array.\n",
    "    The input to this transformer should be a matrix of integers or strings,\n",
    "    denoting the values taken on by categorical (discrete) features.\n",
    "    The features can be encoded using a one-hot aka one-of-K scheme\n",
    "    (``encoding='onehot'``, the default) or converted to ordinal integers\n",
    "    (``encoding='ordinal'``).\n",
    "    This encoding is needed for feeding categorical data to many scikit-learn\n",
    "    estimators, notably linear models and SVMs with the standard kernels.\n",
    "    Read more in the :ref:`User Guide <preprocessing_categorical_features>`.\n",
    "    Parameters\n",
    "    ----------\n",
    "    encoding : str, 'onehot', 'onehot-dense' or 'ordinal'\n",
    "        The type of encoding to use (default is 'onehot'):\n",
    "        - 'onehot': encode the features using a one-hot aka one-of-K scheme\n",
    "          (or also called 'dummy' encoding). This creates a binary column for\n",
    "          each category and returns a sparse matrix.\n",
    "        - 'onehot-dense': the same as 'onehot' but returns a dense array\n",
    "          instead of a sparse matrix.\n",
    "        - 'ordinal': encode the features as ordinal integers. This results in\n",
    "          a single column of integers (0 to n_categories - 1) per feature.\n",
    "    categories : 'auto' or a list of lists/arrays of values.\n",
    "        Categories (unique values) per feature:\n",
    "        - 'auto' : Determine categories automatically from the training data.\n",
    "        - list : ``categories[i]`` holds the categories expected in the ith\n",
    "          column. The passed categories are sorted before encoding the data\n",
    "          (used categories can be found in the ``categories_`` attribute).\n",
    "    dtype : number type, default np.float64\n",
    "        Desired dtype of output.\n",
    "    handle_unknown : 'error' (default) or 'ignore'\n",
    "        Whether to raise an error or ignore if a unknown categorical feature is\n",
    "        present during transform (default is to raise). When this is parameter\n",
    "        is set to 'ignore' and an unknown category is encountered during\n",
    "        transform, the resulting one-hot encoded columns for this feature\n",
    "        will be all zeros.\n",
    "        Ignoring unknown categories is not supported for\n",
    "        ``encoding='ordinal'``.\n",
    "    Attributes\n",
    "    ----------\n",
    "    categories_ : list of arrays\n",
    "        The categories of each feature determined during fitting. When\n",
    "        categories were specified manually, this holds the sorted categories\n",
    "        (in order corresponding with output of `transform`).\n",
    "    Examples\n",
    "    --------\n",
    "    Given a dataset with three features and two samples, we let the encoder\n",
    "    find the maximum value per feature and transform the data to a binary\n",
    "    one-hot encoding.\n",
    "    >>> from sklearn.preprocessing import CategoricalEncoder\n",
    "    >>> enc = CategoricalEncoder(handle_unknown='ignore')\n",
    "    >>> enc.fit([[0, 0, 3], [1, 1, 0], [0, 2, 1], [1, 0, 2]])\n",
    "    ... # doctest: +ELLIPSIS\n",
    "    CategoricalEncoder(categories='auto', dtype=<... 'numpy.float64'>,\n",
    "              encoding='onehot', handle_unknown='ignore')\n",
    "    >>> enc.transform([[0, 1, 1], [1, 0, 4]]).toarray()\n",
    "    array([[ 1.,  0.,  0.,  1.,  0.,  0.,  1.,  0.,  0.],\n",
    "           [ 0.,  1.,  1.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
    "    See also\n",
    "    --------\n",
    "    sklearn.preprocessing.OneHotEncoder : performs a one-hot encoding of\n",
    "      integer ordinal features. The ``OneHotEncoder assumes`` that input\n",
    "      features take on values in the range ``[0, max(feature)]`` instead of\n",
    "      using the unique values.\n",
    "    sklearn.feature_extraction.DictVectorizer : performs a one-hot encoding of\n",
    "      dictionary items (also handles string-valued features).\n",
    "    sklearn.feature_extraction.FeatureHasher : performs an approximate one-hot\n",
    "      encoding of dictionary items or strings.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, encoding='onehot', categories='auto', dtype=np.float64,\n",
    "                 handle_unknown='error'):\n",
    "        self.encoding = encoding\n",
    "        self.categories = categories\n",
    "        self.dtype = dtype\n",
    "        self.handle_unknown = handle_unknown\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"Fit the CategoricalEncoder to X.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like, shape [n_samples, n_feature]\n",
    "            The data to determine the categories of each feature.\n",
    "        Returns\n",
    "        -------\n",
    "        self\n",
    "        \"\"\"\n",
    "\n",
    "        if self.encoding not in ['onehot', 'onehot-dense', 'ordinal']:\n",
    "            template = (\"encoding should be either 'onehot', 'onehot-dense' \"\n",
    "                        \"or 'ordinal', got %s\")\n",
    "            raise ValueError(template % self.handle_unknown)\n",
    "\n",
    "        if self.handle_unknown not in ['error', 'ignore']:\n",
    "            template = (\"handle_unknown should be either 'error' or \"\n",
    "                        \"'ignore', got %s\")\n",
    "            raise ValueError(template % self.handle_unknown)\n",
    "\n",
    "        if self.encoding == 'ordinal' and self.handle_unknown == 'ignore':\n",
    "            raise ValueError(\"handle_unknown='ignore' is not supported for\"\n",
    "                             \" encoding='ordinal'\")\n",
    "\n",
    "        X = check_array(X, dtype=np.object, accept_sparse='csc', copy=True)\n",
    "        n_samples, n_features = X.shape\n",
    "\n",
    "        self._label_encoders_ = [LabelEncoder() for _ in range(n_features)]\n",
    "\n",
    "        for i in range(n_features):\n",
    "            le = self._label_encoders_[i]\n",
    "            Xi = X[:, i]\n",
    "            if self.categories == 'auto':\n",
    "                le.fit(Xi)\n",
    "            else:\n",
    "                valid_mask = np.in1d(Xi, self.categories[i])\n",
    "                if not np.all(valid_mask):\n",
    "                    if self.handle_unknown == 'error':\n",
    "                        diff = np.unique(Xi[~valid_mask])\n",
    "                        msg = (\"Found unknown categories {0} in column {1}\"\n",
    "                               \" during fit\".format(diff, i))\n",
    "                        raise ValueError(msg)\n",
    "                le.classes_ = np.array(np.sort(self.categories[i]))\n",
    "\n",
    "        self.categories_ = [le.classes_ for le in self._label_encoders_]\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        \"\"\"Transform X using one-hot encoding.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like, shape [n_samples, n_features]\n",
    "            The data to encode.\n",
    "        Returns\n",
    "        -------\n",
    "        X_out : sparse matrix or a 2-d array\n",
    "            Transformed input.\n",
    "        \"\"\"\n",
    "        X = check_array(X, accept_sparse='csc', dtype=np.object, copy=True)\n",
    "        n_samples, n_features = X.shape\n",
    "        X_int = np.zeros_like(X, dtype=np.int)\n",
    "        X_mask = np.ones_like(X, dtype=np.bool)\n",
    "\n",
    "        for i in range(n_features):\n",
    "            valid_mask = np.in1d(X[:, i], self.categories_[i])\n",
    "\n",
    "            if not np.all(valid_mask):\n",
    "                if self.handle_unknown == 'error':\n",
    "                    diff = np.unique(X[~valid_mask, i])\n",
    "                    msg = (\"Found unknown categories {0} in column {1}\"\n",
    "                           \" during transform\".format(diff, i))\n",
    "                    raise ValueError(msg)\n",
    "                else:\n",
    "                    # Set the problematic rows to an acceptable value and\n",
    "                    # continue `The rows are marked `X_mask` and will be\n",
    "                    # removed later.\n",
    "                    X_mask[:, i] = valid_mask\n",
    "                    X[:, i][~valid_mask] = self.categories_[i][0]\n",
    "            X_int[:, i] = self._label_encoders_[i].transform(X[:, i])\n",
    "\n",
    "        if self.encoding == 'ordinal':\n",
    "            return X_int.astype(self.dtype, copy=False)\n",
    "\n",
    "        mask = X_mask.ravel()\n",
    "        n_values = [cats.shape[0] for cats in self.categories_]\n",
    "        n_values = np.array([0] + n_values)\n",
    "        indices = np.cumsum(n_values)\n",
    "\n",
    "        column_indices = (X_int + indices[:-1]).ravel()[mask]\n",
    "        row_indices = np.repeat(np.arange(n_samples, dtype=np.int32),\n",
    "                                n_features)[mask]\n",
    "        data = np.ones(n_samples * n_features)[mask]\n",
    "\n",
    "        out = sparse.csc_matrix((data, (row_indices, column_indices)),\n",
    "                                shape=(n_samples, indices[-1]),\n",
    "                                dtype=self.dtype).tocsr()\n",
    "        if self.encoding == 'onehot-dense':\n",
    "            return out.toarray()\n",
    "        else:\n",
    "            return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_attribs = [\"step\"]\n",
    "cat_attribs = [\"department\", \"grade\", \"position_title\", \"positiontype\", \"category\"]\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "        ('selector', DataFrameSelector(num_attribs)),\n",
    "        ('imputer', Imputer(strategy=\"median\")),\n",
    "        ('std_scaler', StandardScaler()),\n",
    "    ])\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "        ('selector', DataFrameSelector(cat_attribs)),\n",
    "        ('cat_encoder', CategoricalEncoder(encoding=\"onehot-dense\")),\n",
    "    ])\n",
    "\n",
    "full_pipeline = FeatureUnion(transformer_list=[\n",
    "        (\"num_pipeline\", num_pipeline),\n",
    "        (\"cat_pipeline\", cat_pipeline),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(['annualsalaryytd', 'name', 'otherpayamt', 'otherpaydesc', 'overtimeamt', 'hire_date', 'annual_salary'], axis=1)\n",
    "y = data[[\"annual_salary\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_transformed = full_pipeline.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_transformed, y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X_train, y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1003.2107461290498"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "lin_mse = mean_squared_error(y_train, lin_reg.predict(X_train))\n",
    "lin_rmse = np.sqrt(lin_mse)\n",
    "lin_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "236734238916901.53"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_mse = mean_squared_error(y_test, lin_reg.predict(X_test))\n",
    "lin_rmse = np.sqrt(lin_mse)\n",
    "lin_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2/variance :  0.995621044238\n",
      "Residual sum of squares: 1006431.80\n"
     ]
    }
   ],
   "source": [
    "predictions_train = lin_reg.predict(X_train)\n",
    "print(\"r2/variance : \", lin_reg.score(X_train, y_train))\n",
    "print(\"Residual sum of squares: %.2f\"\n",
    "              % np.mean((lin_reg.predict(X_train) - y_train) ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2/variance :  -2.52821285125e+20\n",
      "Residual sum of squares: 56043099875564615923895631872.00\n"
     ]
    }
   ],
   "source": [
    "predictions = lin_reg.predict(X_test)\n",
    "print(\"r2/variance : \", lin_reg.score(X_test, y_test))\n",
    "print(\"Residual sum of squares: %.2f\"\n",
    "              % np.mean((lin_reg.predict(X_test) - y_test) ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "department            FIRE DEPARTMENT\n",
       "grade                             PSE\n",
       "position_title    DISTRICT FIRE CHIEF\n",
       "positiontype         Full Time Exempt\n",
       "step                                5\n",
       "category                Public Safety\n",
       "Name: 17, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.iloc[17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3648648306793169\n",
       "Name: 17, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = pd.DataFrame(np.int64(lin_reg.predict(X_test)))\n",
    "pred.iloc[17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "annual_salary                  50251.8\n",
       "annualsalaryytd                5798.29\n",
       "department          CITY INVESTIGATION\n",
       "grade                              A08\n",
       "hire_date          2017-02-24 00:00:00\n",
       "name               BAROUSSE, WILLIAM M\n",
       "otherpayamt                          0\n",
       "otherpaydesc                       NaN\n",
       "overtimeamt                          0\n",
       "position_title       CITY INVESTIGATOR\n",
       "positiontype                 Full Time\n",
       "step                                 4\n",
       "category                 Public Safety\n",
       "Name: 218, dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[218]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>department</th>\n",
       "      <th>grade</th>\n",
       "      <th>position_title</th>\n",
       "      <th>positiontype</th>\n",
       "      <th>step</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>LIBRARY</td>\n",
       "      <td>A02</td>\n",
       "      <td>LIBRARY ASSISTANT I</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>2</td>\n",
       "      <td>Public Works</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>CITY INVESTIGATION</td>\n",
       "      <td>A08</td>\n",
       "      <td>CITY INVESTIGATOR</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>4</td>\n",
       "      <td>Public Safety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>FIRE DEPARTMENT</td>\n",
       "      <td>PSC</td>\n",
       "      <td>FIRE LIEUTENANT</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>5</td>\n",
       "      <td>Public Safety</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             department grade       position_title positiontype  step  \\\n",
       "217             LIBRARY   A02  LIBRARY ASSISTANT I    Full Time     2   \n",
       "218  CITY INVESTIGATION   A08    CITY INVESTIGATOR    Full Time     4   \n",
       "219     FIRE DEPARTMENT   PSC      FIRE LIEUTENANT    Full Time     5   \n",
       "\n",
       "          category  \n",
       "217   Public Works  \n",
       "218  Public Safety  \n",
       "219  Public Safety  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.iloc[217:220]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[           47000],\n",
       "       [           42786],\n",
       "       [           51700],\n",
       "       [           38750],\n",
       "       [           32328],\n",
       "       [           40764],\n",
       "       [           57344],\n",
       "       [           35000],\n",
       "       [           40956],\n",
       "       [           65972],\n",
       "       [           17996],\n",
       "       [           55156],\n",
       "       [           32328],\n",
       "       [           34350],\n",
       "       [           39752],\n",
       "       [           39752],\n",
       "       [           30862],\n",
       "       [3648648306793169]], dtype=int64)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.int64(predictions[:18,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2179    46946.39\n",
       "1525    43117.57\n",
       "1377    50968.74\n",
       "2372    38316.10\n",
       "1125    32318.00\n",
       "1697    40676.69\n",
       "1973    57911.24\n",
       "1027    34567.10\n",
       "929     40894.26\n",
       "210     63243.98\n",
       "1517    18000.00\n",
       "1724    54436.30\n",
       "927     32318.00\n",
       "2028    34599.34\n",
       "1908    39456.35\n",
       "56      39456.35\n",
       "1938    29955.95\n",
       "218     50251.76\n",
       "Name: annual_salary, dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.annual_salary[:18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=int64)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.int64(predictions_train[predictions_train > 155000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-241517544334976.0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA()\n",
    "x2d = pca.fit_transform(X_transformed)\n",
    "cumsum = np.cumsum(pca.explained_variance_ratio_)\n",
    "d = np.argmax(cumsum >= .95) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components = 0.95)\n",
    "x2d = pca.fit_transform(X_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.21619108,  0.1194362 ,  0.07915185,  0.06953584,  0.05091849,\n",
       "        0.03200067,  0.02886885,  0.02676108,  0.02359933,  0.02018242,\n",
       "        0.01715609,  0.01576915,  0.0154829 ,  0.01474405,  0.01316522,\n",
       "        0.01124292,  0.01045958,  0.01027488,  0.00919351,  0.0085542 ,\n",
       "        0.00847718,  0.00754848,  0.00710985,  0.00670706,  0.00602174,\n",
       "        0.00596816,  0.00571172,  0.00543932,  0.00505665,  0.00475863,\n",
       "        0.00454294,  0.00428461,  0.00413338,  0.0040096 ,  0.00387841,\n",
       "        0.0036866 ,  0.00355191,  0.00336307,  0.0031263 ,  0.00307894,\n",
       "        0.00303144,  0.0029289 ,  0.00268351,  0.00262569,  0.00257901,\n",
       "        0.00250444,  0.00242037,  0.00231523,  0.00224006,  0.00210778,\n",
       "        0.00198069,  0.00189523,  0.00177789,  0.00170691,  0.00164992,\n",
       "        0.00161557,  0.00153785,  0.00148242,  0.00147   ,  0.00133834,\n",
       "        0.00122551,  0.00120655,  0.00117313,  0.0011331 ,  0.00106074,\n",
       "        0.0010207 ,  0.00097958,  0.00092351,  0.00087715,  0.00085202,\n",
       "        0.00082474,  0.00080959,  0.0007909 ,  0.00078365,  0.00077011,\n",
       "        0.00075115])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python: can't open file '3': [Errno 2] No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!python 3 -c 'import tensorflow; print(tensorflow.__version__)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting setuptools\n",
      "  Downloading setuptools-38.5.2-py2.py3-none-any.whl (490kB)\n",
      "Installing collected packages: setuptools\n",
      "  Found existing installation: setuptools 36.5.0.post20170921\n",
      "    Uninstalling setuptools-36.5.0.post20170921:\n",
      "      Successfully uninstalled setuptools-36.5.0.post20170921\n",
      "Successfully installed setuptools-38.5.2\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade setuptools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for setuptools\n",
      "Reading https://pypi.python.org/simple/setuptools/\n",
      "Downloading https://pypi.python.org/packages/ad/dc/fcced9ec3f2561c0cbe8eb6527eef7cf4f4919a2b3a07891a36e846635af/setuptools-38.5.2-py2.py3-none-any.whl#md5=abd3307cdce6fb543b5a4d0e3e98bdb6\n",
      "Best match: setuptools 38.5.2\n",
      "Processing setuptools-38.5.2-py2.py3-none-any.whl\n",
      "Installing setuptools-38.5.2-py2.py3-none-any.whl to c:\\users\\595217\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages\n",
      "writing requirements to c:\\users\\595217\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages\\setuptools-38.5.2-py3.6.egg\\EGG-INFO\\requires.txt\n",
      "Adding setuptools 38.5.2 to easy-install.pth file\n",
      "Installing easy_install-script.py script to c:\\users\\595217\\appdata\\local\\continuum\\anaconda3\\Scripts\n",
      "Installing easy_install.exe script to c:\\users\\595217\\appdata\\local\\continuum\\anaconda3\\Scripts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\595217\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages\\setuptools\\pep425tags.py:89: RuntimeWarning: Config variable 'Py_DEBUG' is unset, Python ABI tag may be incorrect\n",
      "  warn=(impl == 'cp')):\n",
      "c:\\users\\595217\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages\\setuptools\\pep425tags.py:93: RuntimeWarning: Config variable 'WITH_PYMALLOC' is unset, Python ABI tag may be incorrect\n",
      "  warn=(impl == 'cp')):\n",
      "error: [WinError 5] Access is denied: 'c:\\\\users\\\\595217\\\\appdata\\\\local\\\\continuum\\\\anaconda3\\\\Scripts\\\\easy_install.exe'\n"
     ]
    }
   ],
   "source": [
    "!easy_install -U setuptools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting distribute\n",
      "  Using cached distribute-0.7.3.zip\n",
      "    Complete output from command python setup.py egg_info:\n",
      "    Traceback (most recent call last):\n",
      "      File \"<string>\", line 1, in <module>\n",
      "      File \"C:\\Users\\595217\\AppData\\Local\\Temp\\pip-build-4dw77r2w\\distribute\\setuptools\\__init__.py\", line 2, in <module>\n",
      "        from setuptools.extension import Extension, Library\n",
      "      File \"C:\\Users\\595217\\AppData\\Local\\Temp\\pip-build-4dw77r2w\\distribute\\setuptools\\extension.py\", line 5, in <module>\n",
      "        from setuptools.dist import _get_unpatched\n",
      "      File \"C:\\Users\\595217\\AppData\\Local\\Temp\\pip-build-4dw77r2w\\distribute\\setuptools\\dist.py\", line 7, in <module>\n",
      "        from setuptools.command.install import install\n",
      "      File \"C:\\Users\\595217\\AppData\\Local\\Temp\\pip-build-4dw77r2w\\distribute\\setuptools\\command\\__init__.py\", line 8, in <module>\n",
      "        from setuptools.command import install_scripts\n",
      "      File \"C:\\Users\\595217\\AppData\\Local\\Temp\\pip-build-4dw77r2w\\distribute\\setuptools\\command\\install_scripts.py\", line 3, in <module>\n",
      "        from pkg_resources import Distribution, PathMetadata, ensure_directory\n",
      "      File \"C:\\Users\\595217\\AppData\\Local\\Temp\\pip-build-4dw77r2w\\distribute\\pkg_resources.py\", line 1518, in <module>\n",
      "        register_loader_type(importlib_bootstrap.SourceFileLoader, DefaultProvider)\n",
      "    AttributeError: module 'importlib._bootstrap' has no attribute 'SourceFileLoader'\n",
      "    \n",
      "    ----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Command \"python setup.py egg_info\" failed with error code 1 in C:\\Users\\595217\\AppData\\Local\\Temp\\pip-build-4dw77r2w\\distribute\\\n"
     ]
    }
   ],
   "source": [
    "!pip install distribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'sudo' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!sudo apt-get install python-setuptools"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
